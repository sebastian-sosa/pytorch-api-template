# FastAPI + PyTorch boilerplate

Have a REST API serving your ML model running in no time!

This repository contains all you need to make your PyTorch model accesible through a
fast REST API, fully customizable and dockerized.

### Runs out-of-the-box

![Cat or dog?](catvdog.png "Cat or dog?")

Already implemented is a fully functional image classifier that will tell you if your
images correspond to cats or dogs. Just run the API server and try the `/predict`
endpoint as explained below.

## How to run the API

You can either run the API in a Docker container or serve it with
[Uvicorn](https://www.uvicorn.org/).

### Prerequisites

1. Install [poetry](https://python-poetry.org/).
2. If serving the API with Uvicorn, run `poetry install` in the cloned repository
   to install all Python dependencies.

### Run with Docker

Running with docker is as easy as running the `build.sh` and `run.sh` scripts already
provided, to build the docker image and run a container. The API should be accesible on
port 8000 of the host machine.

### Run with Uvicorn

Just run `poetry run uvicorn app.main:app --port 8000` on the root directory or:

1. Run `poetry shell` to spawn a shell.
2. Run `uvicorn app.main:app --port 8000` on the project's root directory.

If you want to automatically reload the server when some change is made to the source,
add the `--reload` flag to the `uvicorn` command.


## How to customize the API

Everything is customizable with this API, from the project name to the device where your
PyTorch model is going to run.

### Configuration file

All configuration values can be modified on the `config.yml` file located in the root
directory. To access this values in the code, import the `config` dictionary by adding
`from app.core.config import config` to your module.

Every key and structure added to this file will be accesible through the `config`
dictionary, so you are free to add your own keys as you see fit.

The default values for the keys located in `config.yml` are taken from
`app/core/base_config.yml`. Feel free to modify those also.

### ML models

All models should be located on the `ml_models` directory.

This directory is mounted as a volume in the docker container so the build context
doesn't grow out of proportion. If you put your models somewhere else, expect to see
larger build times when building the docker image.

The model being served by the API is indicated by the key `PATH` under the key `MODEL`
in the `config.yml` file.

To change the actual model you will need to modify the `load_model()` method in the
`app/core/utils.py` module. This method is called at the API startup event to load the
model and make it accesible to all the server workers.

### API endpoints

If you need to customize the endpoint behavior or add new ones, take a look at the
`app/api/` directory. This repository uses FastAPI for building the REST API, so if you
have use it before, maybe the code structure will result familiar to you.
Under `app/api` you will see the following structure:

* [app/api](./app/api)
    * [endpoints](./app/api/endpoints): Here you should put all code for managing the
      API endpoints. Right now you have a `predict.py` module that exposes 2 endpoints
      for classifying cats and dogs, one expects an image as a byte stream and the other
      one base64 encoded.
    * [models](./app/api/models): Here you will see all pydantic models used to define the
      input and output structures used by your API. This is important to use FastAPI's
      automatic structure and type checkings, as well as the autogenerated HTML
      documentation.
    * [utils](./app/api/utils): Contains all utility code used by the endpoints' code.
    * [\_\_init\_\_.py](./app/api/__init__.py): You should modify `app/api/__init__.py` to add a
      router for your new endpoint modules. Otherwise they won't be visible.

## Directory structure

* [app](./app): API server code
  * [api](./app/api): Code related to the API endpoints
  * [core](./app/core): Configuration code
  * [exceptions](./app/exceptions): Defines all custom exceptions that could be raised
* [ml_models](./ml_models): Containes all saved PyTorch models (`.pt` or `.pth` files)
  * [catvdog.pth](./ml_models/catvdog.pth): Weights for the Cats v. Dogs sample model
* [config.yml](./config.yml): User's configuration file
* [Dockerfile](./Dockerfile): Dockerfile for building the API image
* [build.sh](./build.sh): script for building the API image
* [run.sh](./run.sh): script for running a docker container for serving the API
